{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting youtube_transcript_api\n",
      "  Downloading youtube_transcript_api-0.6.1-py3-none-any.whl (24 kB)\n",
      "Requirement already satisfied: requests in /Users/kremenets/anaconda3/lib/python3.11/site-packages (from youtube_transcript_api) (2.29.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/kremenets/anaconda3/lib/python3.11/site-packages (from requests->youtube_transcript_api) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/kremenets/anaconda3/lib/python3.11/site-packages (from requests->youtube_transcript_api) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/kremenets/anaconda3/lib/python3.11/site-packages (from requests->youtube_transcript_api) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/kremenets/anaconda3/lib/python3.11/site-packages (from requests->youtube_transcript_api) (2023.5.7)\n",
      "Installing collected packages: youtube_transcript_api\n",
      "Successfully installed youtube_transcript_api-0.6.1\n"
     ]
    }
   ],
   "source": [
    "!pip install youtube_transcript_api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "\n",
    "openai_api_key = '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'\n",
    "os.environ['OPENAI_API_KEY'] = openai_api_key\n",
    "openai.api_key = openai_api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from youtube_transcript_api import YouTubeTranscriptApi\n",
    "from IPython.display import Markdown, display\n",
    "from llama_index import SimpleDirectoryReader, ServiceContext, PromptHelper, GPTVectorStoreIndex\n",
    "from llama_index import LLMPredictor\n",
    "from langchain.llms import OpenAI\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcription for video SoqVgZjaHNQ saved successfully!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Example usage\n",
    "video_ids = ['SoqVgZjaHNQ']  # Replace with your video IDs\n",
    "folder_path = './data/youtube-transcripts'  # Replace with your desired folder path\n",
    "languages = ['en', 'ru']\n",
    "\n",
    "def get_and_save_transcriptions(video_ids, folder_path, preferred_languages):\n",
    "    \"\"\"\n",
    "    Fetch transcriptions for a list of YouTube video IDs and save them to a folder.\n",
    "    \n",
    "    Args:\n",
    "    - video_ids (list of str): List of YouTube video IDs.\n",
    "    - folder_path (str): Path to the folder where transcriptions will be saved.\n",
    "    \n",
    "    Returns:\n",
    "    - None\n",
    "    \"\"\"\n",
    "    \n",
    "    # Ensure the folder exists\n",
    "    if not os.path.exists(folder_path):\n",
    "        os.makedirs(folder_path)\n",
    "    \n",
    "    for video_id in video_ids:\n",
    "        try:\n",
    "            # Fetch the transcription\n",
    "            transcript = YouTubeTranscriptApi.get_transcript(video_id, languages=preferred_languages)\n",
    "            \n",
    "            # Save the transcription to a file\n",
    "            with open(os.path.join(folder_path, f'{video_id}.txt'), 'w') as file:\n",
    "                for entry in transcript:\n",
    "                    file.write(entry['text'] + ' ')\n",
    "#                     start_time = entry['start']\n",
    "#                     duration = entry['duration']\n",
    "#                     text = entry['text']\n",
    "#                     file.write(f\"{start_time} - {start_time + duration}: {text}\\n\")\n",
    "                    \n",
    "            print(f\"Transcription for video {video_id} saved successfully!\")\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Error fetching transcription for video {video_id}: {e}\")\n",
    "\n",
    "\n",
    "get_and_save_transcriptions(video_ids, folder_path, languages)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_predictor = LLMPredictor(llm=OpenAI(temperature=0))\n",
    "\n",
    "max_input_size = 1024\n",
    "num_outputs = 512\n",
    "max_chunk_overlap = 20 # ??\n",
    "chunk_overlap_ratio = 0.1 # default\n",
    "chunk_size_limit = 512\n",
    "# class llama_index.indices.prompt_helper.PromptHelper\n",
    "# (\n",
    "#  context_window: int = 3900, \n",
    "#  num_output: int = 256, \n",
    "#  chunk_overlap_ratio: float = 0.1, \n",
    "#  chunk_size_limit: Optional[int] = None, \n",
    "#  tokenizer: Optional[Callable[[str], List]] = None, \n",
    "#  separator: str = ' '\n",
    "# )\n",
    "prompt_helper = PromptHelper(max_input_size, num_outputs, chunk_overlap_ratio, chunk_size_limit=chunk_size_limit)\n",
    "\n",
    "service_context = ServiceContext.from_defaults(llm_predictor=llm_predictor, prompt_helper=prompt_helper,chunk_size_limit=chunk_size_limit)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index import VectorStoreIndex, SimpleDirectoryReader\n",
    "documents = SimpleDirectoryReader('./data/youtube-transcripts').load_data()\n",
    "\n",
    "index = VectorStoreIndex.from_documents(documents, service_context=service_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_engine = index.as_query_engine()\n",
    "response = query_engine.query(\"О чем был разговор? насколько можно подробнее\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<b>\n",
       "\n",
       "Разговор был о том, что ведущий прибежал на закрытие и предложил продолжить дискуссию еще на 4 минуты. Они обсуждали, какие книги читать, какие фильмы смотреть и почему это важно, а также о том, как облегчить задачу и привнести нем</b>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(f\"<b>{response}</b>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
